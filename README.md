# 基于深度学习的手势识别系统

一个基于YOLOv5/YOLOv8模型构建的实时手势识别系统，具有用户友好的图形界面。该系统能够从图像、视频和实时摄像头输入中识别手势，具有高精度和实时性能。

## 项目概述

本项目是杭州电子科技大学本科毕业设计作品，旨在探索深度学习在计算机视觉领域的应用，特别是YOLO模型框架在手势识别任务中的实现。系统采用模块化设计，结合Python语言和GUI界面技术，实现了从读取-识别-展示的一站式手势识别应用架构。

## 功能特性

### 核心功能
- **多模型支持**：同时支持YOLOv5n和YOLOv8模型，支持实时模型切换
- **多输入源支持**：
  - 静态图像识别
  - 视频文件处理  
  - 实时摄像头检测
- **手势类别识别**：识别三种主要手势类型
  - Stop（停止手势-张开手掌）
  - NumberTwo（数字二-胜利手势）
  - Understand（理解手势-握拳）

### 系统特性
- **实时性能**：检测时间约0.03秒，支持30 FPS处理
- **交互式GUI**：基于PySide6构建的直观用户界面
- **用户管理**：基于SQLite的登录/注册系统
- **结果记录**：全面的检测结果记录，包含置信度分数和时间戳
- **热力图可视化**：模型注意力区域的可视化展示
- **参数调节**：实时调整置信度和IOU阈值

## 系统要求

### 硬件环境
- **处理器**：Intel Core i9-13900HX 或同等性能
- **显卡**：NVIDIA GeForce RTX 4060 或更高（推荐8GB显存）
- **内存**：最少16GB
- **摄像头**：0.9MP或更高分辨率（用于实时检测）

### 软件环境
- **操作系统**：Windows 10/11 (64位)
- **Python版本**：3.10.14 或更高版本

## 依赖库

```txt
torch==2.0.1
torchvision
ultralytics==8.1.3
opencv-python==4.7.0.72
PySide6
numpy
Pillow
matplotlib
sqlite3
```

## 安装说明

### 1. 克隆项目
```bash
git clone <repository-url>
cd gesture-recognition-system
```

### 2. 创建虚拟环境
```bash
python -m venv venv
# Windows系统
venv\Scripts\activate
# Linux/Mac系统
source venv/bin/activate
```

### 3. 安装依赖
```bash
pip install -r requirements.txt
```

### 4. 下载预训练模型
- 将YOLOv5n模型权重文件放置在 `models/yolov5n.pt`
- 将YOLOv8模型权重文件放置在 `models/yolov8.pt`

### 5. 运行应用程序
```bash
python main.py
```

## 项目结构

```
gesture-recognition-system/
├── data/                           # 数据目录
│   └── model/                      # 预训练模型存放
├── HandGestureDet/                # 主要手势检测项目
│   ├── datasets/                  # 数据集目录
│   │   └── RPS/                   # 石头剪刀布数据集
│   │       ├── test/              # 测试集(图像+标签)
│   │       ├── train/             # 训练集(图像+标签)
│   │       └── valid/             # 验证集(图像+标签)
│   ├── runs/                      # 训练运行结果
│   │   └── detect/                # 各版本训练结果及权重
│   ├── ultralytics/               # Ultralytics YOLO库
│   ├── themes/                    # UI主题文件
│   ├── icons/                     # 图标资源
│   └── weights/                   # 模型权重文件
├── Light-HaGRID/                  # 轻量级HaGRID数据集
│   └── trainval/                  # 训练验证数据
│       ├── call/                  # 通话手势数据
│       ├── dislike/               # 不喜欢手势数据
│       └── fist/                  # 握拳手势数据
├── yolov5/                        # YOLOv5框架
│   ├── data/                      # 数据配置和测试图像
│   ├── models/                    # 模型定义文件
│   ├── runs/                      # YOLOv5训练结果
│   └── utils/                     # 工具函数模块
└── runs/                          # 全局运行结果
└── result/                    # 检测结果输出
```

## 使用方法

### 启动应用程序
1. 运行 `python run_main_login.py`
2. 注册新账户或使用现有凭据登录
3. 选择检测模型（YOLOv5n或YOLOv8）

### 检测模式

#### 图像检测
- 点击"加载图片"按钮
- 选择图像文件（jpg、png等格式）
- 查看带有边界框和置信度分数的检测结果

#### 视频检测
- 点击"加载视频"按钮
- 选择视频文件（mp4、avi等格式）
- 逐帧处理并实时可视化

#### 摄像头检测
- 点击"启动摄像头"按钮
- 执行实时手势识别
- 根据需要调整CONF和IOU阈值

## 模型性能

| 模型 | 精确率 | 召回率 | mAP@0.5 | 检测速度 |
|------|--------|--------|---------|----------|
| YOLOv8 | 95%+ | 95%+ | 0.963 | ~0.03秒 |
| YOLOv5n | 94%+ | 93%+ | 0.940 | ~0.03秒 |

### 训练结果分析
- **损失函数收敛**：边界框损失、分类损失和目标损失均稳定收敛
- **PR曲线表现**：mAP@0.5达到0.963，显示出色的检测性能
- **混淆矩阵**：各类别识别准确率均在95%左右

## 数据集信息

- **数据来源**：基于HaGRID开源数据集
- **图像总数**：11,886张
  - 训练集：10,953张图像
  - 验证集：604张图像
  - 测试集：329张图像
- **图像分辨率**：640×640像素
- **类别分布**：3个手势类别，分布均衡

### 数据预处理
- 自动方向校正，去除EXIF方向信息
- 统一图像尺寸为640×640像素
- 数据增强：包括马赛克增强、旋转、缩放等

## 配置说明

### 可调节参数
- **CONF阈值**：检测的最小置信度分数（默认：0.5）
- **IOU阈值**：非极大值抑制阈值（默认：0.5）
- **帧率**：视频/摄像头输入的处理速度（锁定为30 FPS）

### 模型切换
- 支持YOLOv5n和YOLOv8之间的实时模型切换
- 支持上传自定义训练权重文件

## 系统界面

### 登录注册页面
- SQLite数据库存储用户信息
- 支持用户注册、登录和密码修改
- 验证码机制防止恶意注册

### 主程序界面
- 左侧控制面板：输入源选择、模型切换
- 右侧显示区域：原图预览、热力图显示
- 下方数据表格：检测结果记录和统计
- 顶部参数调节：实时调整CONF和IOU阈值

## 结果与日志

系统提供全面的日志记录功能：
- 检测时间戳
- 置信度分数
- 边界框坐标
- 手势分类结果
- 支持结果导出用于分析

## 技术细节

### 系统架构
- **检测框架**：YOLO（You Only Look Once）
- **深度学习库**：PyTorch 2.0.1
- **计算机视觉**：OpenCV 4.7.0.72
- **GUI框架**：PySide6
- **数据库**：SQLite3

### 训练配置
- **优化器**：AdamW
- **学习率**：动态学习率，包含预热阶段
- **批次大小**：根据硬件自适应
- **数据增强**：马赛克、旋转、缩放等
- **损失函数**：多组件损失（边界框、目标性、分类）

### 核心算法
#### YOLO检测流程
1. 图像预处理：尺寸调整、归一化
2. 特征提取：CNN骨干网络
3. 目标检测：回归边界框和分类概率
4. 后处理：非极大值抑制（NMS）

#### 手势识别流程
1. 输入源读取（图像/视频/摄像头）
2. 数据预处理
3. 模型推理
4. 结果后处理
5. 可视化显示

## 已知限制

- 在不同光照条件下性能可能有所差异
- 识别精度依赖于手部可见度和手势清晰度
- 当前实现限制为三种手势类别
- 复杂背景可能影响检测精度

## 未来改进方向

### 功能扩展
- **更多手势类别**：扩展支持更多种类的手势识别
- **跨文化适应**：研究不同文化背景下的手势差异
- **移动端部署**：优化模型以支持移动设备部署
- **多模态输入**：集成语音、文本等其他信息模态

### 技术优化
- **模型轻量化**：基于神经网络架构搜索（NAS）技术优化模型
- **实时性提升**：进一步优化推理速度
- **鲁棒性增强**：提高在复杂环境下的识别稳定性

## 开发贡献

1. Fork 项目仓库
2. 创建功能分支 (`git checkout -b feature/new-feature`)
3. 提交更改 (`git commit -am 'Add new feature'`)
4. 推送到分支 (`git push origin feature/new-feature`)
5. 创建 Pull Request

## 许可证

本项目作为杭州电子科技大学本科毕业设计作品开发。使用和分发请参考学校相关规定。

## 致谢

- **指导教师**：张新老师
- **协助指导**：Zhdanov Andrey老师（俄罗斯ITMO大学）
- **学院**：杭州电子科技大学圣光机学院
- **专业**：计算机科学与技术
- **数据集**：HaGRID开源手势数据集
- **技术框架**：Ultralytics YOLO、PyTorch、OpenCV开源社区

## 联系方式

如有问题或建议，请联系开发团队或参考原始论文文档。

---

**注意**：本系统主要用于研究和教育目的。性能可能因硬件配置和环境条件而有所差异。

## 附录

### 常见问题解决

**Q: 模型加载失败**
A: 检查模型文件路径是否正确，确保模型文件完整

**Q: 摄像头无法启动**  
A: 检查摄像头权限设置，确保摄像头未被其他程序占用

**Q: 检测精度不理想**
A: 调整CONF和IOU阈值，确保光照条件良好

**Q: 系统运行缓慢**
A: 检查GPU驱动是否正确安装，考虑使用更轻量的模型

### 系统性能优化建议

1. **硬件优化**：使用支持CUDA的NVIDIA显卡
2. **环境配置**：确保PyTorch正确识别GPU
3. **参数调优**：根据实际需求调整模型参数
4. **内存管理**：及时清理不用的变量和缓存

### 扩展开发指南

本系统采用模块化设计，便于功能扩展：

- **新增手势类别**：修改数据集和模型训练配置
- **界面定制**：基于PySide6框架进行UI设计
- **算法替换**：实现YOLOv8v5Detector接口即可集成新算法
- **数据库扩展**：基于SQLite可扩展更多用户功能
